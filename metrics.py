"""
performance metrics function
"""


def mean(item):
    """
    Calculate the mean of the list
    :param item: list object
    :return:
    """
    res = float(sum(item)) / float(len(item)) if len(item) > 0 else 0
    return res


def accuracy(pred_y, true_y):
    """
    Calculate accuracy
    :param pred_y: predict result
    :param true_y: true result
    :return:
    """
    if isinstance(pred_y[0], list):
        pred_y = [item[0] for item in pred_y]
    # print(pred_y)
    # print(true_y)
    corr = 0
    for i in range(len(pred_y)):
        if pred_y[i] == true_y[i]:
            corr += 1

    acc = float(corr) / float(len(pred_y)) if len(pred_y) > 0 else 0
    return acc


def binary_precision(pred_y, true_y, positive=1):
    """
    Calculate the precision of binary classification
    :param pred_y: predict result
    :param true_y: true result
    :param positive: index of positive label
    :return:
    """
    corr = 0
    pred_corr = 0
    for i in range(len(pred_y)):
        if pred_y[i] == positive:
            pred_corr += 1
            if pred_y[i] == true_y[i]:
                corr += 1

    prec = float(corr) / float(pred_corr) if pred_corr > 0 else 0
    return prec


def binary_recall(pred_y, true_y, positive=1):
    """
    Calculate the recall of binary classification
    :param pred_y: predict result
    :param true_y: true result
    :param positive: index of positive label
    :return:
    """
    corr = 0
    true_corr = 0
    for i in range(len(pred_y)):
        if true_y[i] == positive:
            true_corr += 1
            if pred_y[i] == true_y[i]:
                corr += 1

    rec = float(corr) / float(true_corr) if true_corr > 0 else 0
    return rec


def binary_f_beta(pred_y, true_y, beta=1.0, positive=1):
    """
    Calculate the f beta of binary classification
    :param pred_y: predict result
    :param beta: beta parameter
    :param true_y: true result
    :param positive: index of positive label
    :return:
    """
    precision = binary_precision(pred_y, true_y, positive)
    recall = binary_recall(pred_y, true_y, positive)
    try:
        f_b = (1 + beta * beta) * precision * recall / (beta * beta * precision + recall)
    except:
        f_b = 0
    return f_b


def get_binary_metrics(pred_y, true_y, f_beta=1.0):
    """
    Calculate various performance metrics of binary classification
    :param pred_y: predict result
    :param true_y: true result
    :param f_beta: beta parameter
    :return:
    """
    acc = accuracy(pred_y, true_y)
    recall = binary_recall(pred_y, true_y)
    precision = binary_precision(pred_y, true_y)
    f_beta = binary_f_beta(pred_y, true_y, f_beta)
    return acc, recall, precision, f_beta


def multi_precision(pred_y, true_y, labels):
    """
    Calculate the precision of multi classification
    :param pred_y: predict result
    :param true_y: true result
    :param labels: label list
    :return:
    """
    if isinstance(pred_y[0], list):
        pred_y = [item[0] for item in pred_y]

    precisions = [binary_precision(pred_y, true_y, label) for label in labels]
    prec = mean(precisions)
    return prec


def multi_recall(pred_y, true_y, labels):
    """
    Calculate the recall of multi classification
    :param pred_y: predict result
    :param true_y: true result
    :param labels: label list
    :return:
    """
    if isinstance(pred_y[0], list):
        pred_y = [item[0] for item in pred_y]

    recalls = [binary_recall(pred_y, true_y, label) for label in labels]
    rec = mean(recalls)
    return rec


def multi_f_beta(pred_y, true_y, labels, beta=1.0):
    """
    Calculate the f value of multi classification
    :param pred_y: predict result
    :param true_y: true result
    :param labels: label list
    :param beta: beta parameter
    :return:
    """
    if isinstance(pred_y[0], list):
        pred_y = [item[0] for item in pred_y]

    f_betas = [binary_f_beta(pred_y, true_y, beta, label) for label in labels]
    f_beta = mean(f_betas)
    return f_beta


def get_multi_metrics(pred_y, true_y, labels, f_beta=1.0):
    """
    Calculate various performance metrics of multi classification
    :param pred_y: predict result
    :param true_y: true result
    :param labels: label list
    :param beta: beta parameter
    :return:
    """
    acc = accuracy(pred_y, true_y)
    recall = multi_recall(pred_y, true_y, labels)
    precision = multi_precision(pred_y, true_y, labels)
    f_beta = multi_f_beta(pred_y, true_y, labels, f_beta)
    return acc, recall, precision, f_beta